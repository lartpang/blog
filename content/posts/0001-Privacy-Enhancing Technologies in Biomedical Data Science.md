---
title: "Privacy-Enhancing Technologies in Biomedical Data Science"
date: 2024-10-26 13:48:07
tags: ["paper"]
---

<!--more-->

> <https://github.com/lartpang/blog/issues/23>

## 1. 引言

数据共享是生物医学创新的重要推动力。公共数据仓库和生物银行使不同组织的研究人员能够分析他们自己可能无法收集的大量人类主体数据。许多学术实验室、商业企业和医院已经联合起来形成合作联盟，共享生物医学数据，希望从数据集中提取出由于数据集规模有限而无法被单个实体访问的洞察。政府实体（例如，美国国立卫生研究院数据管理和共享政策；<https://sharing.nih.gov>）和国际标准制定组织如全球基因组学和健康联盟（1）制定的政策和指南在维护生物医学界的数据共享文化中发挥了关键作用，这一传统根植于人类基因组计划等里程碑式的合作努力中。

随着我们进入个性化医疗时代，生物医学数据的更广泛共享变得比以往任何时候都更加重要。现有生物医学数据集中所代表的人类群体的多样性有限，加剧了不同群体从生物医学进步中获益的不平等（2）。研究罕见疾病通常需要合并跨组织的小型患者队列以增强统计能力（3）。此外，准确推断与每个独特个体相关的健康洞察需要访问在大型和多模态数据集上训练的计算模型，这些数据集捕捉了健康和疾病中个体变化的广泛范围。尽管最近创建的生物银行 [例如，All of Us 研究计划（4）] 在招募多样化的研究参与者方面迈出了重要一步，但这些资源越来越多地存储在孤立的计算环境中，限制了这些数据集的范围和使用。

为了进一步扩大生物医学领域的数据共享工作，必须用强有力的缓解措施解决日益增长的隐私风险。没有这些措施，我们可能会看到对受限数据孤岛的更大依赖，这种情况因最近更严格的隐私法规的激增（例如，欧盟的通用数据保护条例（GDPR]）和生物医学数据规模及计算进步带来的风险增加而进一步加剧。此外，大规模数据泄露可能会侵蚀公众对科学企业的信任。信任的丧失不仅可能阻碍收集大型数据集的努力，还可能通过不成比例地影响某些人群参与研究的意愿而加剧不平等。

隐私增强技术（PETs）提供了有希望的技术解决方案，通过采用各种数学、算法和硬件设计方法，使敏感数据的共享和分析成为可能，同时保护隐私（图 1）。PETs 涵盖了广泛的技术，这些技术解决了不同的数据共享场景，并在支持的分析类型、计算成本和提供的隐私保护程度方面引入了各种权衡。在这篇综述中，我们专注于文献中最广泛研究的技术，包括同态加密（HE）、安全多方计算（MPC）、可信执行环境（TEE）、差分隐私（DP）和联邦学习（FL）。最近的进展极大地增加了这些技术在生物医学领域的适用性，正如我们在这篇综述中所说明的。与将 PETs 描述为解决生物医学数据共享挑战的潜在解决方案的现有综述（5-9）不同，我们专注于提供 PETs 最新进展的易于理解的总结，检查其技术基础和生物医学应用。

这篇综述的其余部分组织如下。第 2 节介绍了生物医学数据隐私的背景，涵盖了其历史背景和关键概念。第 3 节概述了涉及数据共享的生物医学研究场景。第 4 节深入探讨了每种 PET，提供了技术概述、最新进展、局限性和最近出版物，并探索了其在生物医学任务中的应用。第 5 节回顾了有助于促进生物医学数据共享的相关技术。最后，在第 6 节中，我们通过讨论开放性挑战和突出未来工作的关键方向来结束。

## 2. 生物医学数据隐私：挑战和现有保障

生物医学领域的数据隐私挑战在过去几十年中不断演变，受到技术进步、公众意识提高和政策法律变化的影响。从 1960 年代到 1980 年代，生物医学界见证了人体研究伦理原则的建立，如贝尔蒙特报告（10）所体现的文件。与此同时，由于医疗记录的数字化，对患者隐私的关注增加。1990 年代见证了通用规则和健康保险流通与责任法案（HIPAA）（11）的建立，标志着为保护研究和医疗保健中的生物医学数据而创建法律框架的初步努力。人类基因组计划的完成和 2000 年代遗传研究的快速增长加剧了对人类主体及其遗传隐私保护的关注。2010 年代见证了更广泛的社会背景下隐私问题的激增，这些担忧由社交媒体的兴起、大规模数据泄露和围绕政府监控的争议（12, 13）引发。国际社会通过加强对个人信息收集、共享和使用的监督来回应这些担忧，例如 2018 年颁布的 GDPR。更近的例子包括亚利桑那州和加利福尼亚州 2021 年的遗传隐私法律（14），这些法律加强了存储和共享遗传数据的隐私要求，以及国家标准与技术研究院的基因组网络安全倡议（<https://www.nccoe.nist.gov/projects/cybersecurity-genomic-data>），该倡议呼吁在基因组学中制定新的安全标准。目前，隐私问题持续存在并扩展到新的生物医学领域，如数字健康 [例如，电子健康记录（EHR）、移动应用和可穿戴设备]、多组学和 COVID-19 大流行后的流行病响应（15）。大型生物银行和数据仓库的数量不断增加，进一步放大了这些挑战。

生物医学数据泄露的风险是多方面的。虽然个人对可接受的隐私风险有不同的看法，但未经授权的暴露与个人生物学和健康相关的私密信息可能导致情感困扰、污名化和在就业、教育和保险机会中的歧视。也许更令人担忧的是，这些伤害可能会扩展到家庭和人口群体，例如，通过披露个人之间的遗传关系或群体内较高的健康风险。从管理敏感生物医学数据的组织的角度来看，数据泄露可能导致罚款、法律后果、运营中断和声誉损害。这些风险不仅仅是假设性的——在撰写本文时，已对 23andMe 提起诉讼，原因是数据泄露泄露了近 100 万客户的信息，包括他们的全名、出生日期和 DNA 档案，这些信息在暗网上被出售，每个泄露的个人高达 10 美元（16）。如果这种泄露事件重演，将导致对生物医学研究企业和卫生系统的信任下降，这将进一步阻碍未来的研究工作，阻碍科学进步。

生物医学隐私泄露可能通过多种途径发生，每个途径都带来独特的挑战（8, 17）。表型推断旨在从不同类型的生物医学数据中推断出个人的特征或健康状况，通常是以意想不到的方式。再识别发生在不足以匿名化的数据被重新链接回个人时。这可能涉及结合多个数据集、利用辅助信息或利用去识别过程中的漏洞。数据链接整合了不同数据集的信息，构建了个人的更全面资料，允许攻击者揭示身份、健康状况或其他敏感信息。即使不直接共享包括个人层面信息的完整数据集，隐私仍可能被泄露：数据重建攻击试图组装可用信息的片段以揭示原始数据的一部分；成员资格推断攻击专注于确定个人是否属于特定数据集，这可能透露该人是否属于敏感或污名化的群体，可能导致隐私侵犯。

保护生物医学数据隐私的传统方法包括政策和法律、技术安全措施和合同协议。法律和财务处罚有助于防止生物医学信息的滥用；HIPAA 和 GDPR 都为不合规规定了这样的处罚。保护生物医学数据的标准做法涉及对静态数据进行加密、采用安全的计算基础设施和去识别策略（18）。访问控制和用户认证机制也被广泛使用，以确保只有授权的个人才能访问敏感数据。此外，共享敏感数据的研究人员和组织通常会建立数据使用协议（DUAs）来定义数据的允许使用和数据管理指南。类似地，业务关联协议，即 HIPAA 覆盖实体（例如，医院）和它们的业务关联（例如，第三方服务提供商或合作伙伴）之间的合同，是确保处理受保护健康信息的实体遵守数据保护标准的的重要工具。

尽管这些方法为生物医学数据提供了有用的保障，但它们并没有消除数据泄露或再识别的可能性，主要依赖于限制对数据的访问来实现安全，这导致许多数据集被隔离并置于大多数研究人员无法触及的地方。此外，检测违规行为和执行处罚的能力在实践中可能受到限制；确定哪些数据被视为私密或足够去识别以共享的法律和政策标准缺乏明确的定义。因此，许多现有的数据集要么基于信任不安全地共享，要么由于隐私风险被认为不适合共享。

## 3. 数据共享场景和限制

隐私风险和数据共享限制在生物医学研究和实践的不同场景中各不相同。在这里，我们概述了典型的数据共享场景（如图 1 所示）以及每个背景下利益相关者面临的挑战。

### 3.1. 研究参与

个人可能自愿为研究（无论是临床还是非临床）、数据仓库和第三方服务贡献健康数据和其他个人信息。参与者通常提供知情同意，其中概述了数据共享的细节，包括目的、范围和涉及的潜在风险。数据共享使参与者受益，因为它提高了对健康和疾病的集体理解，可能导致更好的治疗或其他健康相关决策。在某些服务的背景下，参与者也可能获得个性化的数据洞察。隐私关注是个人决定参与研究的一个关键因素（19）。知情同意的充分性仍然是一个持续辩论的话题，特别是关于获取广泛同意用于数据的二次使用（20）的伦理问题。有效地传达隐私风险也可能具有挑战性，因为一些风险需要技术专长才能完全理解，甚至在研究人员中也知之甚少。

### 3.2. 可查询数据库

可查询数据库专门设计为允许用户通过查询检索信息，为访问生物医学数据提供结构化和高效的方式。例子包括用于研究招募的患者注册表和包含注释遗传变异的各种数据库（21）、EHR（22）和临床试验数据（23）。虽然查询的限制性质最小化了信息泄露，但研究表明，即使有这些限制，意外的披露仍然可能发生（24）。这样的担忧可能会阻碍个人参与这些数据库，并可能对数据库提供商构成数据管理挑战。

### 3.3. 分析服务

这指的是将计算任务委托给可以访问受限模型或数据资源或更多计算资源的外部实体的做法。生物医学分析工作流程的日益增长的计算需求促使研究人员越来越多地使用这些第三方服务（25），其中许多服务托管在云环境中。然而，隐私问题或法规可能限制这些服务的使用（例如，希望将数据上传到在非欧盟国家运营的服务的欧盟研究人员）。此外，服务提供商可能需要引入措施来保护服务器使用的辅助模型和数据，这些模型和数据可能通过返回给用户的分析结果泄露（26）。

### 3.4. 合作研究

不同机构或国家的研究人员越来越需要通过合并数据来共享研究目标，以获得对感兴趣的生物医学现象更完整的理解。这种场景通常涉及建立专注于特定健康状况或研究领域的联盟。然而，组织可能需要遵守限制或禁止数据外部共享的政策，如果实体在不同的监管环境或国家中运营，这个问题会加剧。

### 3.5. 公共数据发布

这涉及使生物医学数据集和分析结果对更广泛的科学界和公众公开可访问。这种做法支持科学研究的透明度和可重复性，并促进了数据科学竞赛（例如，Kaggle；<https://www.kaggle.com/>）等合作努力。它还通过允许全球的研究人员重新分析现有数据，扩展了收集的数据集的效用。然而，发布包含个人层面信息的数据集存在极大的隐私风险，并且只有在罕见的情况下才可行。在发布基于部分私有数据的模拟或编辑数据集时，也必须小心，因为这些数据集仍可能导致隐私泄露。

### 3.6. 公共卫生监测

COVID-19 大流行促使设计能够监测疾病爆发并促进响应（例如，暴露通知应用程序）的公共卫生系统。这些系统的有效运行可能需要收集广泛的个人信息，包括健康状况之外的人口统计、地理位置和社会活动数据。此外，跨管辖区共享这些数据可能对于更准确地了解传染病代理是必要的。然而，由于披露私密信息可能对个人造成伤害的可能性仍然是一个重大关切（15），这可能阻止这些系统的广泛采用。

## 4. 隐私增强技术及其在生物医学中的应用

PETs 代表了一类计算技术，用于保护敏感的生物医学数据。总的来说，这些技术使开发用于共享和分析生物医学数据的隐私设计方法成为可能。这些方法提高了生物医学数据的隐私和效用，超出了现有安全实践和合同保障（例如，DUAs）所可行的范围。我们详细描述了每项技术，并讨论了最近的技术进步和在生物医学领域中的应用。

### 4.1. 安全多方计算

MPC 允许多个参与方共同在他们的私有输入上执行计算，而不会向彼此透露输入。MPC 主要使用两种技术：混乱电路和秘密共享。

1986 年，姚（Yao）首次介绍了混乱电路（27），它允许在两个拥有私有输入的参与方之间安全地评估一个函数，该函数表示为布尔电路。混乱电路中的每个逻辑门的输入和输出都是随机掩蔽的，以防止评估器在电路评估过程中获得信息。一方的输入使用称为无意识传输的密码原语安全地传达给另一方，然后允许接收者在不知道原始输入的情况下评估电路。尽管对于复杂的分析任务，电路大小的指数级扩展通常会导致高通信和计算成本，但几项增强（28-31）已经提高了这些方案的效率（32-34）。

秘密共享方案（35, 36）允许一组参与方共同对一个私有数字进行编码，将其划分为由各方单独持有的随机份额。只有当预定义数量的份额结合时，才能重建私有数字。例如，在实际设置中最常用的加法秘密共享方案中，秘密份额是环（一个代数结构，由一组整数模某个特定数字表示）的随机元素，它们加起来等于私有值。这确保了只有当所有参与方的份额结合时才能揭示秘密；任何子集都不会透露可以用来推断秘密的信息。安全地添加两个秘密共享数字，x 和 y，涉及每个参与方添加他们各自的 x 和 y 份额，从而产生代表 x + y 的新份额。安全乘法需要参与方之间的交互（37），但通过掩蔽各方之间共享的数字来保护私有输入的保密性。其他操作，如除法、平方根和比较，是使用加法、乘法和利用私有值的位表示的特殊例程执行的。这些操作可以结合使用，以安全地执行多个参与方持有的私有数据的各种分析。

已经开发了许多框架和编译器，以简化利用各种构建块协议的 MPC 算法的实现（38）。混合方案（39, 40）和编译器（32, 38, 41），结合不同的 MPC 方法以提高效率，也已经提出。例如，ABY（41）提出了在混乱电路和不同类型的秘密共享（整数或布尔）之间切换，以在最高效的域中执行每个操作（例如，在两方设置中使用混乱电路评估比较，或在涉及超过两方的其他位操作中使用布尔秘密共享）。这些框架已经扩展和优化，用于机器学习（ML）应用，如神经网络模型的训练和推理（42-45）。核心操作（46）的最新增强进一步提高了 MPC 框架的性能和多功能性。

MPC 的主要限制是其大量的通信成本。虽然混乱电路允许大部分计算通过单轮通信非交互性地执行，但电路通常限于布尔操作，对于复杂的数值计算，电路的大小可能变得不切实际的大。与混乱电路相比，秘密共享通常在一般情况下提供更大的分析灵活性和效率，但基于秘密共享的 MPC 通常需要许多轮交互来完成复杂任务，这可能是有限通信设置（例如，具有大往返延迟的广域网）的潜在瓶颈。此外，要求在整个输入数据集中秘密共享的要求可能是大规模生物医学数据集的一个障碍。

最近的工作已经开发了 MPC 协议，用于生物医学领域的一系列分析任务（47-52）。这些工作的共同目标是通过重新设计分析任务，使其更适用于使用 MPC 操作进行高效计算，从而提高 MPC 的效率。例如，Cho 等人（47）引入了秘密共享技术的一种泛化，旨在最小化冗余计算，从而实现了一种高效的全基因组关联研究（GWAS）算法，涉及复杂的线性代数任务，如主成分分析。这项工作被扩展到使用神经网络模型进行药物 - 靶标相互作用的协作预测（53）。Jagadeesh 等人（49）使用混乱电路有效地执行布尔操作（如集合交集和差集），以识别患者基因组中感兴趣的遗传变异。Von Maltitz 等人（54）引入了一种基于 Kaplan-Meier 估计器的生存分析的 MPC 协议。Smajlovi´c 等人（55）采取了不同的方法，开发了一种基于 Python 的编译器，将高级分析代码转换为 MPC 可执行文件，结合基于静态代码分析的自动优化。这些工具可以帮助加速 MPC 应用程序的开发，用于各种生物医学任务，通过使技术对生物医学从业者更易于访问。

### 4.2. 同态加密

HE 指的是一种加密形式，它允许在加密数据上直接进行计算。早期的 HE 方案，如 Rivest 等人（56）、Elgamal（57）、Paillier（58）和 Goldwasser & Micali（59）的方案，被称为分层或某种 HE 方案，支持特定类型的操作，例如，仅加法或仅乘法，或者有限数量的操作。2009 年，Gentry（60）引入了第一个完全同态加密（FHE）方案，它通过一种自举技术，允许任意算术计算，该技术刷新密文（加密数据）以支持额外的操作。为了解决 Gentry 最初方案的有限具体效率问题，该方案需要每比特操作几分钟的运行时间（61），后来提出了几个方案（62-65），降低了 FHE 的整体计算成本，从而使其在实际应用中得以使用。

与标准加密方案类似，HE 的安全性基于对研究充分的数学问题的难度。许多 HE 方案基于环学习误差（RLWE）问题（66, 67），这是一个基于格的问题，目标是区分一组环元素是随机采样的，还是近似于将已知一组元素与一个共同的秘密元素相乘的结果。这个问题被证明在不知道秘密的情况下极其难以解决，但否则很容易，转化为只有知道解密密钥的实体才能解密密文的保证。引入到密文中的随机噪声，以保持这个问题的难度，随着每次同态操作而增加。与精确执行计算以牺牲减少编码值范围的方案（62-64）不同，Cheon 等人（65）的 CKKS 方案直接将噪声添加到数据值中，实现了在小精度损失下的有效操作。CKKS 已在可以容忍少量噪声的科学应用中得到广泛采用。在所有基于 RLWE 的方案中，单个密文编码多个值，并且同态操作如加法和乘法同时在密文中的所有值上执行——被称为单指令多数据属性。利用这一属性可以提高这些方案的可扩展性。

值得注意的最新发展包括更有效的自举技术（68, 69）和提供不同类型操作之间权衡的替代构造。例如，Chillotti 等人（70）基于环的数学结构构建的 TFHE 方案，允许有效的自举，但限于布尔或位操作。此外，已经提出了几个 HE 编译器（71），以简化 HE 算法的开发和优化，例如，简化密文噪声的管理。还为安全训练预测性 ML 模型（72, 73）开发了定制框架。

在生物医学领域，HE 主要应用于涉及敏感数据的计算任务的外包。这些计算可能因问题规模（就数据集大小和计算复杂性而言）或对分析所需的额外数据或模型的有限访问而对个人用户来说具有挑战性。HE 有助于确保用户的数据在委托给第三方进行分析时保持私密。例如，已经提出了基于 HE 的解决方案，用于私密外包心电图数据中的心脏状况检测，以及基于健康记录的心血管风险预测。许多工作已经解决了在加密数据上计算 GWAS 统计量的问题，涉及一系列统计量和应用设置（76-80）。文献中探索的其他任务包括对基因组和医疗数据库的计数查询（例如，用于队列探索）（81, 82），检测遗传亲子关系（83），以及使用临床和基因组信息进行疾病风险预测（74, 84）。最后，Kim 等人（85）和 Gürsoy 等人（86）最近展示了对加密私有基因组的安全插补。

这些进步使基于 HE 的解决方案更接近满足生物医学应用的要求。然而，由于几个因素，这些应用的范围仍然受到限制，包括与未加密分析相比同态操作的大量计算开销、需要使用加法和乘法近似非线性操作，以及由于自举的高成本而对分析任务的复杂性的实际限制。此外，大多数上述解决方案要求将所有输入数据加密并传输给执行计算的实体，这对于大型数据集可能是一个重大负担。在标题为“扩展同态加密到协作分析设置：多方同态加密”的侧边栏中，我们描述了最近的一项技术进步，有助于解决这些限制。

### 4.3. 可信执行环境

TEE 是主处理器内的安全区域，也称为飞地，它确保软件的安全和隔离执行。这种隔离保证了内存内容、与外部实体的端到端通信以及应用程序的控制流受到保护，不受同一硬件上运行的不受信任或恶意进程的影响，包括恶意操作系统或虚拟机管理程序（103, 104）。在某些 TEE 体系结构中，应用程序的二进制可执行文件也可以通过称为远程认证的过程进行验证（105）。为了实现这些安全属性，TEE 依赖于内置于处理器的核心硬件安全组件，这些组件不能被软件操纵。这些组件通常包括一个内存加密引擎和控制器以隔离内存访问，以及用于加密密钥存储和操作的集成电路。

最近的 TEE 发展集中在支持在不受信任的云环境中部署第三方软件，解决用户级应用程序和虚拟机（VM）的部署。流行的 TEE 平台包括 Intel Software Guard Extension（SGX）（106）用于用户级应用程序，以及 Intel Trust Domain Extensions（107）和 AMD Secure Encrypted Virtualization（108）用于 VM。Nvidia 最近推出了其图形处理单元（GPU）架构的更新，使 GPU 计算能够在 TEE 中进行（109）。在移动环境中，Arm TrustZone（104）是 Arm 中央处理单元（CPU）上无处不在的 TEE 平台，但通常移动应用程序可用的 TEE 功能集有限。

尽管 TEE 提供了在类似传统计算环境中保密分析私有数据的能力和功能，它们的主要缺点在于实现基于硬件的安全的复杂性。与依赖于最小且确立的密码原语的 MPC 和 HE 不同，TEE 的基于硬件的方法引入了独特的漏洞。一些漏洞是由于 CPU 架构错误导致的，这些错误允许恶意进程从飞地中提取受保护的数据（110）；制造商通常会在发现这些问题后立即修补。其他限制是 TEE 体系结构固有的，导致了侧信道问题——信息泄露的间接途径（111, 112）。例如，TEE 飞地对内存页面的访问模式可能会无意中向攻击者泄露存储在安全区域内的敏感信息。尽管这类攻击需要大量的努力，但在需要最高安全级别的软件级别缓解是必要的。一种策略是确保程序的内存访问或时序模式不依赖于敏感信息（113）。然而，这种缓解可能会增加额外的计算负担，并在算法开发过程中需要相关专业知识。

尽管存在这些缺点，TEE 有着光明的未来，主要 CPU 生产商如 Intel、AMD 和 Arm 对它们有着浓厚的兴趣，他们继续解决安全问题并改进他们的 TEE 平台。云服务提供商如 Google Cloud Platform 和 Microsoft Azure 提供 TEE 启用的计算基础设施。此外，还成立了诸如机密计算联盟（<https://confidentialcomputing.io>）和互联网工程任务组的可信执行环境配置（TEEP）工作组（<https://datatracker.ietf.org/wg/teep/about>），以支持与 TEE 相关的开源项目和标准开发。在研究社区中，近年来引入了许多软件工具，以简化现有软件转换为在 TEE 平台上安全运行的过程（112）。

在生物医学领域，TEE 由于其能够安全地外包生物医学数据分析，并促进在大规模上开发和部署健康人工智能（AI）工具，已经获得了显著的吸引力。值得注意的真实世界例子包括 BeeKeeperAI（114），这是一家保护隐私的医疗保健 AI 公司，以及 AOK，这是德国 11 个地区健康保险公司的网络。这些组织利用 Intel SGX 来保护机密患者数据，遵守 HIPAA、GDPR 和德国患者数据保护法（115）等法规。基因组学中 TEE 的应用也在出现。一个例子是基于 Intel SGX 的联合 GWAS 服务，它安全地聚合来自多个站点的数据，并随着研究参与者的增加或减少而逐步更新统计数据（116）。还提出了增强 Intel SGX 中 GWAS 计算效率的数据草图技术（117）。考虑到其他基因组分析任务，Widanage 等人（118）在 Intel SGX 中展示了读取映射，并描述了将他们的工具概括化为其他工作流程。Dokmai 等人（113）提出了一种基于 TEE 的安全基因型插补服务，引入了在保持准确的插补性能的同时实现对侧信道攻击的弹性的技术。

### 4.4. 差分隐私

DP 是隐私的数学定义，它通过确保数据集中移除或添加单个个体不会导致分析结果的可区分变化，从而提供严格的隐私保护（119,120）。形式上，给定ε ≥ 0，一个随机机制 A 满足ε-DP，如果对于所有相差一个记录的数据集 D1 和 D2，以及 A 的任何可能输出子集 O，我们有 P [A(D1) ∈ O] ≤ e^εP [A(D2) ∈ O]——直观地说，这意味着在相似的数据集之间，任何结果的可能性都是相似的。参数ε称为隐私预算，用于指定隐私保护的水平。DP 机制通常通过向数据添加噪声来满足隐私保证，其中较小的ε提供更多的隐私，以增加噪声的方式牺牲准确性。标准 DP 技术包括拉普拉斯、高斯和指数机制，代表不同的采样噪声分析结果的方法。

已经开发了各种技术来最小化噪声添加，并在隐私和效用之间获得更可取的权衡。例如，一些 DP 公式放宽了隐私概念以获得更好的效用：(ε, δ)-DP，也称为近似 DP（120），要求以至少 1 − δ的概率满足ε-DP。集中 DP（121）、零集中 DP（122）和 Rényi DP（123）将隐私损失视为一个随机变量，并限制平均损失而不是最坏情况损失。

DP 的关键属性包括后处理，它确保对满足 DP 的数据的进一步分析不会导致任何额外的隐私泄露，以及组合，它允许在相同数据上操作的多个机制结合起来提供联合 DP 保证。因此，向分析管道的不同组件添加 DP 噪声——例如，输入、输出、优化目标（124, 125）或梯度（126, 127）——可以根据分析任务对整体精度产生重大影响。影响噪声量的另一个关键因素是灵敏度，它测量由于数据中单个记录的变化而导致的分析输出的最大变化。已经提出了不同的方法来分析给定函数的灵敏度 [例如，全局、局部或平滑灵敏度（128）]。由于这些考虑，通常需要为特定应用程序精心设计 DP 机制以优化其性能。

例如，在多方设置中，DP 可以由各个数据提供者本地实施，也可以由聚合分析结果的中央服务器全局实施；这些方法分别称为本地差分隐私（LDP）和集中差分隐私（CDP）。尽管 CDP 通常需要较少的噪声，通过直接向聚合数据添加噪声，但它可能更容易受到隐私泄露的影响，因为它依赖于受信任的第三方进行数据聚合。另一方面，LDP 在单个数据提供者级别提供 DP，同时增加了整体噪声量。实现 LDP 的常见数据扰动技术包括随机响应及其变体（129-131）。

最近，各种实体已经部署了 DP 来解决私有统计数据的收集和发布隐私化数据集。Erlingsson 等人（132）的 RAPPOR 技术使用随机响应和布隆过滤器从 Chrome 浏览器私密地收集使用统计数据。Apple 已经部署了 LDP 来收集其设备上的 emoji 和搜索查询信息（133），Microsoft 也在 Windows 10 中用于应用程序级遥测（134）。2020 年，美国人口普查局使用 TopDown 算法（135）发布了带有 DP 的人口普查数据，该算法基于地理单位层次地聚合统计数据。

DP 在生物医学应用中的关键重点之一是发布 GWAS 统计数据。Uhlerop 等人（136）引入了用于发布病例对照 GWAS 的最小等位基因频率和χ2 统计量的 DP 机制。这项工作后来由 Yu 等人（137, 138）扩展到处理更大的队列和逻辑回归。还提出了一种基于指数机制的替代方法（139）。Simmons & Berger（140）引入了一个优化框架，用于私密报告固定数量的最显著关联。在后续工作中，Simmons 等人（141）开发了具有人口分层校正的 GWAS 的 DP 方法。DP 的其他值得注意的应用包括共享基因型数据（142）、临床试验数据（143）和表格医疗记录（144）。DP 也已应用于交互式数据库设置，例如计数或成员资格查询（145, 146）和患者遗传匹配（147）。在公共卫生领域，DP 已被用于支持 COVID-19 实时信息系统的准备工作和流行病响应（148）以及冠状动脉心脏病的移动诊断系统（149）。

尽管取得了这些进展，DP 的实际采用面临几个技术挑战。与 DP 方法相关的隐私参数（例如，ε）是控制隐私和效用之间权衡的重要因素；然而，没有严格的选择这些参数的可接受值的方法或标准，用于给定任务。由于生物医学数据通常是高维的，需要私密共享的统计数据数量很大。此外，这些数据通常使用许多步骤的复杂算法进行分析，其中可以整合 DP。因此，设计有效的 DP 机制，以最佳方式分配隐私预算可能是困难的。另一个限制是 DP 不能保护每个数据集；例如，小型数据集通常需要大量的噪声进行 DP，需要使用其他策略进行保护。

### 4.5. 联邦学习

FL 允许多个参与方以分布式方式协作训练机器学习（ML）模型。参与方在训练期间共享模型参数或更新（例如，梯度），但不直接共享训练数据，从而减轻隐私风险。FL 用例的两个主要类别包括（a）跨数据孤岛，其中少数参与方持有大量数据，以及（b）跨设备，其中大量设备（可能数百万）持有少量数据（150）。前者更类似于传统的 MPC 设置，其中参与方可能代表不同机构，每个机构都从许多个体中收集数据，而后者通常在消费者应用中发现，例如，数百万移动电话可能收集个人用户数据。

在 FL 中，每个参与方在评估和更新模型时仅限于其本地数据份额；因此，存在几种同步参与方模型状态的方法。联邦平均技术要求每个参与方本地计算模型更新，这些更新被发送到中央服务器进行平均，并全局应用（151）。用于平均这些更新的权重通常根据每个参与方的数据大小和质量选择（152, 153）。更高级的方法，如联邦匹配平均，通过匹配进行层级同步，以应对神经网络中的排列不变性（154）。其他方法避免全局同步，而是迭代地将权重从一个参与方传递到另一个参与方（155）。个性化 FL 是另一种方法，每个参与方学习一个不同的本地模型，该模型结合了来自其他参与方的信息和本地数据特征（156, 157）。

FL 的鲁棒性在实践中是一个主要挑战。网络连接、通信限制和资源限制等问题可能会阻止某些参与方完全参与协议的每一轮（158, 159）。数据孤岛或设备之间的异质性也可能引入关于训练模型的公平性和泛化性的担忧；例如，简单的平均技术已被证明会导致小亚群组中的不准确结果（160-162）。

另一个挑战是 FL 可能提供有限的隐私和安全保护。例如，通过检查其他参与方在协议多轮中的模型更新，一个医院可能能够推断出另一个医院患者的特征。这可能揭示有关临床标签分布、特征向量中个别坐标的信息，有时甚至可以揭示整个训练输入（164-166）。此外，恶意对手可能会操纵数据或模型以推进自己的目标，牺牲他人的利益（167）。

最近关于 FL 的文献引入了广泛的技术来解决这些限制。将 FL 与 DP 结合可以提供有关隐私泄露的严格界限（168, 169），尽管在保持模型准确性的同时这样做可能是具有挑战性的。如果中央聚合器不受信任，参与方可以选择使用 LDP 向其本地梯度添加噪声，然后再聚合（170）。或者，MPC、HE 或 TEE 也可以支持安全聚合模型权重，以便除了聚合结果外不会泄露任何额外信息（163）。还提出了使用加密技术在整个训练过程中保护模型参数的解决方案（96-98）。鲁棒性通常通过根据每个参与方的质量调整协议来解决。例如，一些方法建议检测和删除异常值，从一组可靠的参与方中学习。其他人建议改变平均权重，以产生在每个参与方上表现相当好的更公平的全局模型（162）。尽管现有的 FL 应用主要集中在监督学习上，但最近的工作将 FL 扩展到解决其他 ML 任务，包括半监督、无监督和强化学习（171-173）。

FL 已经触及了许多生物医学应用。在跨数据孤岛设置中，FL 可以通过结合更广泛的训练数据来改善不同阶段患者的分析和护理，从而提高 ML 模型的性能。值得注意的用途包括罕见疾病分析（174, 175）、多医院合作进行医学图像分析（176-178）以及从临床笔记中自动表型化和风险预测（179-181）。在跨设备设置中，FL 有潜力转变移动健康（182）。例如，FL 可以允许可穿戴设备，如 Fitbits 或 Apple Watches，随着时间的推移适应个人独特的健康和生活方式特征，如静息心率、每天的步数和血氧水平。这些模型可以为个人提供更准确的健康监测，例如步态识别和跌倒检测（183, 184）。

## 5. 其他相关技术

涉及私有数据交换的几个工作流程已经引起了隐私和安全社区的特别关注，以开发超出第 4 节中描述的 PETs 范围的针对性方法。在这一节中，我们强调了一些这样的技术。

### 5.1. 私密信息检索

在私密信息检索（PIR）中，客户端从一个存储在服务器上的数据库中检索特定的感兴趣项目，而不会透露访问项目的标识（185, 186）。下载整个数据库并本地查询的朴素方法对于大型数据集来说是不切实际的。在基于 HE 的解决方案中，客户端上传一个加密的查询，服务器同态地搜索数据库，然后返回结果供客户端解密。通过实际的基于格的 HE（第 4.2 节）和数据库预处理以及摊销技术（187, 188），最近的 PIR 协议已经显示出可以扩展到包含数十亿条目的数据库（189-192）。其他工作已经将 PIR 扩展到更复杂的查询，如在稀疏数据库中的关键词搜索（193, 194）和批量查询（195, 196）。在生物医学背景下，PIR 可以增强需要用户要么下载整个数据库，要么向服务器披露私有数据（例如，遗传突变或患者记录）才能查询数据库的公共数据资源的效用。例如，已经提出了用于外包基因组数据存储的 PIR 解决方案，这些解决方案支持安全检索感兴趣的变异（197, 198）。

### 5.2. 私密集合交集

私密集合交集（PSI）解决了与 PIR 密切相关的问题，其中两个参与方，每个都持有一组项目，希望了解这两组之间的交集，而不向彼此透露任何其他信息。PSI-size 是 PSI 的一个显著变体，其中只揭示交集的大小。PSI 已经得到了广泛的研究，导致实际协议适用于数十亿项目，并提出了几种变体，涉及不同的信任假设、通信和计算之间的权衡，以及参与方的数量（199-201）。几项工作提出了用于计算基因组相似性的 PSI 协议，将每个基因组视为一组变异：Baldi 等人（202）引入了基于 PSI 技术的亲子鉴定（203, 204），Wang 等人（205）开发了一种基于 PSI 的协议，用于安全计算基因组之间的编辑距离。

### 5.3. 零知识证明

在涉及敏感生物医学数据时，验证计算的正确性可能具有挑战性。零知识证明（ZKP）（206）是一种密码原语，与 MPC 和数字签名（56, 207）相关，允许在不披露敏感信息的情况下证明关于数据或计算的陈述的真实性。例如，Goldreich 等人（208）表明，通用 ZKP（209）可以用来证明安全计算协议（例如，MPC）在不解密任何中间值的情况下诚实地执行。尽管通用构造通常会产生不切实际的计算开销，但最近的进步已经提高了在各种安全和模型假设下 ZKP 的效率（210-213）。Froelicher 等人（214）展示了用于离散对数的 ZKP（215）可以确保分布式健康分析系统中某些 HE 计算的完整性。Chatel 等人（216）引入了一种基于 MPC-in-the-head 范式（217, 218）的 ZKP 方案，允许直接向消费者分析服务提供商验证用户上传的数据来自受信任的来源，从而防止恶意用户篡改分析结果。

### 5.4. 区块链

区块链提供了一个去中心化的框架，用于安全地记录和验证分布式网络中的交易。它使用密码技术创建区块链，即时间戳交易列表，提供数据管理的透明度、不可变性和可问责性。除了在金融领域（例如，比特币）的众所周知的应用外，区块链在生物医学领域也变得越来越相关（219）。一个关键用例是创建一个安全且去中心化的健康信息交换，以改善各种参与者之间的医疗记录和保险索赔的管理（220）。它还可以用来创建一个数据共享平台，以支持生物医学研究，同时提供数据来源和可问责性（221）。通过区块链交换的数据的隐私保护是一个关键挑战，通常需要仔细结合其他加密技术或 PETs。正在进行的另一项研究重点是提高区块链网络的可扩展性和鲁棒性，这对于它们在大型机构网络中的部署是必要的。

### 5.5. 合成数据生成

创建与真实数据相似但不直接链接到私有个体的合成数据已成为一种有用的隐私意识数据共享策略（222）。公共共享的合成数据可以支持合作努力，如数据分析竞赛和跨机构的计算模型验证。它还可以支持各种学术和教育活动，例如，通过创建用于培训或公共沟通的真实患者资料。随着 ML 的进步，特别是深度生成模型的发展，生成合成数据的技术也在不断发展。生成对抗网络和扩散模型的引入大大提高了各种类型生物医学数据的合成，包括医学图像（223, 224）和 EHR（225）。然而，合成数据可能泄露用于训练模型的原始数据的私有信息的可能性仍然是一个主要关注点（226）。最近的研究建议，现代生成模型的更大表现力实际上增加了私有训练数据被重建的可能性（227）。虽然将 DP 纳入模型训练可以帮助减轻这些风险（228），但它可能会降低生成数据的质量，特别是对于高维数据，如图像和基因组。未来在合成数据的质量和隐私方面的改进对于扩大它们在需要直接共享数据的环境中的使用至关重要。

## 6. 开放性挑战和展望

随着生物医学数据科学的领域扩展到包含更多样化的数据模式、更复杂的统计模型和不断演变的计算环境，我们对隐私风险的理解也必须改变。揭示新兴数据类型（例如，转录组学（84, 229-231）、蛋白质组学（232）和可穿戴设备（233））和计算模型（例如，扩散和大型语言模型（227, 234））中的新隐私风险的研究将特别有价值。将这些发现整合到实际指导方针和政策中将需要深思熟虑地检查潜在对手不断演变的动机和能力（235-237）。

PETs 的一个关键方面是它们提供的不同程度的隐私保护，以及它们如何与我们的社会价值观和实践者的需求保持一致。虽然承认提供最强大、最正式隐私概念的密码 PETs（即 HE、MPC 和 DP）的价值，我们还必须意识到这些技术在实际实施中的潜在陷阱，例如软件缺陷（238）或违反模型假设（239）。提供较少形式但更广泛适用的隐私增强技术（即 TEE 和 FL）可以在某些设置中作为有用的替代方案。一个有希望的未来方向是探索 PETs 的联合使用，以结合它们的优势，同时减轻它们的弱点，如在标题为“扩展同态加密到协作分析设置：多方同态加密”的侧边栏中所述。未来的政策和法规将在将基于 PETs 的新兴工具的复杂隐私属性转化为生物医学社区的具体指导方针中发挥关键作用。

PETs 的社会影响涉及另一个关键考虑因素：公平性（240）。许多研究表明，计算工具在新兴的临床应用中存在不平等（241, 242）。解决这些问题需要更大的数据共享，以创建更多样化的数据集，这反过来又引入了新的隐私挑战（243, 244）。另一方面，那些最需要数据以改善生物医学公平性的人（例如，代表性不足的群体）在隐私泄露事件中可能遭受的损失最大（245）。此外，某些 PETs，如 DP，可能会不成比例地降低数据集中代表性有限的人群的 ML 模型的准确性（246）。在隐私和公平之间导航这种复杂的权衡仍然是一个重要的挑战。

我们期望信任和透明度在将 PETs 与组织环境中利益相关者的利益一致方面发挥关键作用（247）。PETs 可以被视为加强利益相关者之间信任的工具，通过增加透明度和减轻合作伙伴关系中出现的各種隐私和安全风险。这与 PETs 社区通常关注防止恶意行为者破坏系统并获得对敏感数据的访问的焦点形成对比。将诸如信任和以人为中心的设计原则等情境价值整合到 PETs 中，可以促进创建更有效地解决生物医学社区需求的工具。

随着 PETs 的不断成熟和更广泛的适用性，如本综述所示，将有越来越多的需求定制这些技术，以创建有效的算法和工具，解决多样化的生物医学工作流程。PET 开发者、生物医学从业者、政策制定者以及患者和研究参与者之间的更紧密合作，可以帮助优先考虑解决最紧迫挑战的努力。此外，旨在协助研究人员将 PETs 纳入其现有工作流程的软件开发和部署工具，可以帮助确保这些技术被广泛接受。基础技术的进步、有效的算法设计以及建立社会框架以保障这些技术的使用，将是解锁 PETs 在生物医学数据科学中潜力的关键。
