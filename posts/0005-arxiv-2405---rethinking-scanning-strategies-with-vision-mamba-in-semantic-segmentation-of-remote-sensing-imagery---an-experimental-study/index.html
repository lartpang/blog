<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta http-equiv=content-language content="en-us"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>ArXiv 2405 - Rethinking Scanning Strategies with Vision Mamba in Semantic Segmentation of Remote Sensing Imagery - An Experimental Study &#183; 啊，哈！</title>
<meta name=title content="ArXiv 2405 - Rethinking Scanning Strategies with Vision Mamba in Semantic Segmentation of Remote Sensing Imagery - An Experimental Study &#183; 啊，哈！"><meta name=description content="Just for fun."><meta name=keywords content="paper,"><link rel=canonical href=https://lartpang.github.io/blog/posts/0005-arxiv-2405---rethinking-scanning-strategies-with-vision-mamba-in-semantic-segmentation-of-remote-sensing-imagery---an-experimental-study/><link type=text/css rel=stylesheet href=/blog/css/main.bundle.min.01dde6ff86a3d23e6258a134912503c50666955af42c932ac894e1b1bd4644de893c078daf8e692391173d9351000cbc001451e378e0a8ccc240295b9ed5a0f8.css integrity="sha512-Ad3m/4aj0j5iWKE0kSUDxQZmlVr0LJMqyJThsb1GRN6JPAeNr45pI5EXPZNRAAy8ABRR43jgqMzCQClbntWg+A=="><link rel=apple-touch-icon sizes=180x180 href=/blog/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/blog/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/blog/favicon-16x16.png><link rel=manifest href=/blog/site.webmanifest><meta property="og:url" content="https://lartpang.github.io/blog/posts/0005-arxiv-2405---rethinking-scanning-strategies-with-vision-mamba-in-semantic-segmentation-of-remote-sensing-imagery---an-experimental-study/"><meta property="og:site_name" content="啊，哈！"><meta property="og:title" content="ArXiv 2405 - Rethinking Scanning Strategies with Vision Mamba in Semantic Segmentation of Remote Sensing Imagery - An Experimental Study"><meta property="og:description" content="Just for fun."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-17T11:08:54+00:00"><meta property="article:modified_time" content="2024-05-17T11:08:54+00:00"><meta property="article:tag" content="Paper"><meta name=twitter:card content="summary"><meta name=twitter:title content="ArXiv 2405 - Rethinking Scanning Strategies with Vision Mamba in Semantic Segmentation of Remote Sensing Imagery - An Experimental Study"><meta name=twitter:description content="Just for fun."><script defer type=text/javascript src=/blog/lib/fuse/fuse.min.1f56d60a7738743270762a2aa4e0a453be99c4476f06f3b2f51f4377d12a7ed973420f76a308d7e4855d88ec34d25940c9015464934faf30e7599fe566d7f6e4.js integrity="sha512-H1bWCnc4dDJwdioqpOCkU76ZxEdvBvOy9R9Dd9EqftlzQg92owjX5IVdiOw00llAyQFUZJNPrzDnWZ/lZtf25A=="></script><link rel=preload href=https://lartpang.github.io/blog/fonts/Ubuntu-Regular.woff2 as=font type=font/woff2 crossorigin><script>const siteTheme="auto";let savedTheme=localStorage.getItem("theme")||siteTheme;savedTheme=="auto"&&window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&(savedTheme="dark"),savedTheme==="dark"&&(document.documentElement.classList.add("dark"),localStorage.setItem("theme","dark"))</script></head><body><div class=content><header><a class=title href=/blog/><img loading=lazy src=https://avatars.githubusercontent.com/u/26847524 alt="Site Logo"></a><div class=header-cntr><a class=title href=/blog/><span>啊，哈！</span></a><div class=menu><nav id=main-menu class=mm-normal><ul><li><button id=mob-x-icon class=menu-btn arial-label=x-icon><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></button></li><li><a href=/blog/posts/ aria-label=posts>Posts</li></a><li><a href=/blog/tags/ aria-label=tags>Tags</li></a><li><a href=/blog/about/ aria-label=about>About</li></a><li><a href=https://github.com/lartpang aria-label=github><span><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></li></a></ul></nav><div class=side-menu><button id=search-open class=menu-btn aria-label="Search button"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></button><div id=search-container data-url=https://lartpang.github.io/blog/><div class=search><div class=panel><form><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
<input type=search id=search-query placeholder=Search tabindex=0 autocomplete=off>
<button id=search-close title="Cancel (ESC)"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></button></form></div><ul id=search-results></ul><div id=search-overlay></div></div></div><button id=theme-switcher class=menu-btn aria-label="Theme switcher"><div id=moon><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></div><div id=sun><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></div></button></div><button id=mob-hb-icon class=menu-btn aria-label="Hamburger icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></button></div><script>(function(){document.addEventListener("DOMContentLoaded",function(){const s=document.getElementById("mob-hb-icon"),e=document.getElementById("mob-x-icon"),t=document.getElementById("main-menu"),n=document.body;s.addEventListener("click",function(){t.classList.replace("mm-normal","mm-mobile-open"),e.style.display="block",n.style.overflow="hidden"}),e.addEventListener("click",function(){t.classList.replace("mm-mobile-open","mm-normal"),e.style.display="none",n.style.overflow=""})})})()</script><script>(function(){var t,n,e=document.getElementById("main-menu");if(!e)return;t=window.location.pathname,n=e.querySelectorAll("a"),n.forEach(function(e){e.getAttribute("href")===t&&e.classList.add("active")})})()</script></div></header><main><ul class=breadcrumbs><li><a href=https://lartpang.github.io/blog/><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M575.8 255.5c0 18-15 32.1-32 32.1h-32l.7 160.2c0 2.7-.2 5.4-.5 8.1v16.2c0 22.1-17.9 40-40 40h-16c-1.1.0-2.2.0-3.3-.1-1.4.1-2.8.1-4.2.1L416 512h-24c-22.1.0-40-17.9-40-40v-24-64c0-17.7-14.3-32-32-32h-64c-17.7.0-32 14.3-32 32v64 24c0 22.1-17.9 40-40 40h-24-31.9c-1.5.0-3-.1-4.5-.2-1.2.1-2.4.2-3.6.2h-16c-22.1.0-40-17.9-40-40V360c0-.9.0-1.9.1-2.8v-69.7h-32c-18 0-32-14-32-32.1.0-9 3-17 10-24L266.4 8c7-7 15-8 22-8s15 2 21 7L564.8 231.5c8 7 12 15 11 24z"/></svg></a></li><li><a href=https://lartpang.github.io/blog/posts/>Posts</a></li></ul><h1 class=pg-title>ArXiv 2405 - Rethinking Scanning Strategies with Vision Mamba in Semantic Segmentation of Remote Sensing Imagery - An Experimental Study</h1><div class=meta><p><span class=meta-icon><svg fill="currentcolor" width="800" height="800" viewBox="0 0 24 24"><path d="M19 4H17V3a1 1 0 00-2 0V4H9V3A1 1 0 007 3V4H5A3 3 0 002 7V19a3 3 0 003 3H19a3 3 0 003-3V7A3 3 0 0019 4zm1 15a1 1 0 01-1 1H5a1 1 0 01-1-1V12H20zm0-9H4V7A1 1 0 015 6H7V7A1 1 0 009 7V6h6V7a1 1 0 002 0V6h2a1 1 0 011 1z"/></svg>
</span>Posted on <time datetime=2024-05-17T11:08:54+00:00>May 17, 2024</time>
<span class=meta-icon><svg width="800" height="800" viewBox="0 0 24 24" fill="currentcolor"><path d="M23 12c0 6.0751-4.9249 11-11 11C5.92487 23 1 18.0751 1 12 1 5.92487 5.92487 1 12 1c6.0751.0 11 4.92487 11 11zM3.00683 12c0 4.9668 4.02638 8.9932 8.99317 8.9932 4.9668.0 8.9932-4.0264 8.9932-8.9932.0-4.96679-4.0264-8.99317-8.9932-8.99317-4.96679.0-8.99317 4.02638-8.99317 8.99317z" fill="currentcolor"/><path d="M12 5C11.4477 5 11 5.44771 11 6v6.4667S11 12.7274 11.1267 12.9235C11.2115 13.0898 11.3437 13.2343 11.5174 13.3346l4.6198 2.6673C16.6155 16.278 17.2271 16.1141 17.5032 15.6358 17.7793 15.1575 17.6155 14.5459 17.1372 14.2698L13 11.8812V6C13 5.44772 12.5523 5 12 5z" fill="currentcolor"/></svg>
</span>2 mins</p><p><span class=meta-icon><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M48 32H197.5c17 0 33.2 6.74 45.2 18.75l176 175.95c25 25 25 65.6.0 90.6L285.3 450.7c-25 25-65.6 25-90.6.0L18.75 274.7C6.743 262.7.0 246.5.0 229.5V80C0 53.49 21.49 32 48 32zm64 144c17.7.0 32-14.3 32-32 0-17.7-14.3-32-32-32-17.67.0-32 14.3-32 32s14.33 32 32 32z"/></svg>
</span><a class=tag href=/blog/tags/paper/>Paper</a></p></div><div class=toc><details><summary accesskey=c title=(Alt+C)>Table of Contents</summary><div class=toc-innr><nav id=TableOfContents><ul><li><a href=#实验设置>实验设置</a></li><li><a href=#对-patch-和-stride-的实验>对 patch 和 stride 的实验</a></li><li><a href=#对扫描策略的实验>对扫描策略的实验</a></li><li><a href=#总结>总结</a></li></ul></nav></div></details></div><ul><li>Author: lartpang</li><li>Link: <a href=https://github.com/lartpang/blog/issues/19 target=_blank>https://github.com/lartpang/blog/issues/19</a></li></ul><h1 id=rethinking-scanning-strategies-with-vision-mamba-in-semantic-segmentation-of-remote-sensing-imagery---an-experimental-study>Rethinking Scanning Strategies with Vision Mamba in Semantic Segmentation of Remote Sensing Imagery - An Experimental Study
<a hidden class=anchor href=#rethinking-scanning-strategies-with-vision-mamba-in-semantic-segmentation-of-remote-sensing-imagery---an-experimental-study><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg></a></h1><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715940900574-31a0605b-a575-435a-b812-95c9a914d28f.png#averageHue=%23e2e2e1&amp;clientId=u366ffa07-da0f-4&amp;from=paste&amp;height=255&amp;id=u2f6d91e6&amp;originHeight=319&amp;originWidth=1207&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=106541&amp;status=done&amp;style=none&amp;taskId=uec6996b9-51be-4818-b72c-9c843e4f91b&amp;title=&amp;width=965.6" alt=image.png></p><ul><li>论文：<a href=https://arxiv.org/pdf/2405.08493 target=_blank>https://arxiv.org/pdf/2405.08493</a></li><li>原始文档：<a href=https://github.com/lartpang/blog/issues/19 target=_blank>https://github.com/lartpang/blog/issues/19</a></li></ul><p>深度学习方法，尤其是卷积神经网络 (CNN) 和视觉变换器 (ViT)，经常用于执行高分辨率遥感图像的语义分割。然而，cnn 受到其有限的接受领域的限制，而 vit 由于其二次复杂性而面临挑战。最近，具有线性复杂性和全局感受野的 mamba 模型在视觉任务中获得了广泛的关注。在此类任务中，需要对图像进行序列化以形成与 mamba 模型兼容的序列。许多研究工作已经探索了扫描策略来序列化图像，旨在增强 Mamba 模型对图像的理解。然而，这些扫描策略的有效性仍然不确定。</p><p>在这项研究中，我们对主流扫描方向及其组合对遥感图像语义分割的影响进行了全面的实验研究。通过在 LoveDA，ISPRS Potsdam 和 ISPRS Vaihingen 数据集上进行的广泛实验，我们证明，**无论其复杂性或所涉及的扫描方向数量如何，都没有单一的扫描策略能胜过其他扫描策略。简单的单个扫描方向被认为足以对高分辨率遥感图像进行语义分割。**还建议了未来研究的相关方向。</p><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715941629150-8eaa3d1c-3cba-4c1c-8859-8db0d6d70ab5.png#averageHue=%23aeaea2&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=543&amp;id=Z52RW&amp;originHeight=679&amp;originWidth=780&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=756594&amp;status=done&amp;style=none&amp;taskId=u5b50fc8b-4c05-436c-b839-a43ec2e0135&amp;title=&amp;width=624" alt=image.png></p><p>这份工作主要做了两点内容：</p><ul><li>总结了现有视觉 mamba 中常用的 12 种独立的序列化扫描方向，并实验了 22 中不同策略（12 个独立的和 10 个组合变体）。</li><li>第一次基于特定设计的实验架构，在三个数据集上定量对比探究了视觉 mamba 不同扫描策略对遥感图像的语义分割准确性的影响。</li></ul><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715941784993-b8281602-4f51-491d-8c18-7c3a37ca68de.png#averageHue=%23f9f9f8&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=764&amp;id=u9592ffaa&amp;originHeight=955&amp;originWidth=1285&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=335531&amp;status=done&amp;style=none&amp;taskId=ueccd0ac2-864f-4d48-9f97-b37373ff52a&amp;title=&amp;width=1028" alt=image.png></p><p>展示了现有方法的几种不同策略</p><p>**这些努力都是基于这样的假设，即图像补丁的不同扫描方向可以潜在地增强 Mamba 对图像的理解。**但是，在他们的工作中，缺乏对不同扫描方向下的模型性能进行全面和定量的比较。</p><ul><li>Vim 和 PlainMamba 缺乏必要的消融研究来验证其扫描方法。</li><li>在 VMamba 中，水平扫描组合的结果 (即，D1 和 D2) 没有报告，而四方向扫描 (即，与单向扫描 D1 相比，D1、D2、D3 和 D4) 在 ImageNet 上仅实现了 0.3% 高的精度。考虑到训练过程中模型性能的可能波动，这种边际改进不足以证实多向扫描的有效性。</li></ul><p>而在分割任务的研究中，一些工作考虑了不同的扫描策略来测试它们对 mamba 图像理解能力的影响。</p><ul><li>U-Mamba 代表了将 Mamba 与 UNet 架构合并以进行医学图像语义分割的首次尝试。但是，由于其简单的建筑设计，其性能不及当时最先进的分割方法。</li><li>随后，出现了几种增强的方法使用 Vim 的双向扫描和/或使用 VMamba 的四向扫描。</li><li>在遥感领域，Samba 是第一个将 Mamba 引入遥感图像语义分割的研究，其中图像补丁以与 ViT 相同的方式进行展平，如图 2(a)。</li><li>后来，RS3Mamba 使用 VMamba 的四向扫描方法，构造了一个用于语义分割的辅助编码器。</li><li>同样，RSMamba 在的编码器 - 解码器体系结构中添加四个额外的对角线方向 (即，D5，D6，D7 和 D8) 。</li></ul><h2 id=实验设置>实验设置
<a hidden class=anchor href=#%e5%ae%9e%e9%aa%8c%e8%ae%be%e7%bd%ae><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg></a></h2><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715941557406-7054055b-0bd7-411f-8388-c80bdc6506db.png#averageHue=%23f3ecd1&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=500&amp;id=dDFBJ&amp;originHeight=625&amp;originWidth=805&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=156361&amp;status=done&amp;style=none&amp;taskId=ufe785803-f442-4729-97a2-91977bff0a2&amp;title=&amp;width=644" alt=image.png></p><p>实验所使用的架构形式</p><p>图像划分为 patch，序列送入四个 VMS（Vision Mamba Scan）模块顺次下采样。并使用 UperNet 作为解码器预测分割结果。这里为了使用单个模型兼容所有的扫描组合形式，当所考虑的扫描方向的数目为 1、2 或 4 时，扫描方向分别重复 8、4 和 2 次，以填充八个潜在的扫描方向。（这个重复是否会对最终的性能有影响尚未可知）</p><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715942682479-fab9935b-7221-4843-9706-20af588cf4d8.png#averageHue=%23f9f8f7&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=391&amp;id=u169ebbbe&amp;originHeight=489&amp;originWidth=1119&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=88686&amp;status=done&amp;style=none&amp;taskId=u4413d1ab-ca0f-406c-add1-fcbad8e3f67&amp;title=&amp;width=895.2" alt=image.png></p><p>三个数据集的训练设置</p><ul><li>Random resize, random crop, random flip, and photometric distortion are consistently applied for data augmentation in our experiments.</li><li>Experiments are performed using two RTX 4090D GPUs.</li></ul><h2 id=对-patch-和-stride-的实验>对 patch 和 stride 的实验
<a hidden class=anchor href=#%e5%af%b9-patch-%e5%92%8c-stride-%e7%9a%84%e5%ae%9e%e9%aa%8c><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg></a></h2><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715942738707-8e63c622-be07-402f-859e-0693664531c2.png#averageHue=%23f7f5f4&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=360&amp;id=u9b4a23f6&amp;originHeight=450&amp;originWidth=1282&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=127683&amp;status=done&amp;style=none&amp;taskId=u5a61e942-973e-490e-a920-b5e216e5da7&amp;title=&amp;width=1025.6" alt=image.png></p><p>**用于图像裁剪的补丁大小和扫描过程中使用的步幅也会影响实验结果。**目前，大多数基于 mamba 的视觉任务都采用 4×4 大小的 patch 和 4 的步幅。为了探索最适合后续实验的补丁大小和步幅，本研究在三个数据集上进行了各种变体的消融实验。<strong>为了进行一致的比较，在消融实验中使用了 D1 扫描方向。</strong></p><p>**步幅也起着至关重要的作用，因为它会影响序列的长度和计算负荷。**这里使用 FLOPs 量化计算负载，这是使用一个随机生成的 512×512 图像作为输入来计算的。加倍步幅将需要计算的像素数减少了四倍，从而使计算减少了大约四倍。</p><p>考虑到实用性，实验中最小步幅设为 4，较小步幅需要过高的计算资源，因此在两个 24G GPU 上进行训练是不切实际的。实验中考虑的 patch 大小包括 4×4、8×8、16×16 和 32×32，每个配对的步幅与相应的 patch 大小相同，用于分割整个图像。此外，还考虑了小于 patch 尺寸的步幅，这可以允许图像的重叠扫描。</p><p>表 II 列出了由各种修补尺寸和步幅组合的分割精度。从三个数据集的性能分析中可以看到一致的发现：当处理 512×512 的图像输入尺寸时，步幅为 4 的 4×4 补丁大小可产生所有三个数据集的最高分割精度。当将步幅依次减小到 4 并保持固定的 patch 大小，mamba 在处理这些长序列时没有出现瓶颈，这表明它有潜力有效处理更小的步幅。因此，mamba 在处理较小步幅的长序列方面显示出希望。固定步幅后，减小 patch 大小可改善分割性能，这表明 mamba 架构更擅长处理更精细的图像补丁。基于这些发现，在随后的实验中始终使用 4x4 的 patch 大小和 4 的步幅 (即，实验 1- 实验 22)。</p><h2 id=对扫描策略的实验>对扫描策略的实验
<a hidden class=anchor href=#%e5%af%b9%e6%89%ab%e6%8f%8f%e7%ad%96%e7%95%a5%e7%9a%84%e5%ae%9e%e9%aa%8c><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg></a></h2><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715942760785-86492410-d4de-4b7c-8d0e-a512ecf72d32.png#averageHue=%23e5e5e5&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=323&amp;id=uf11cadd5&amp;originHeight=404&amp;originWidth=1250&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=197766&amp;status=done&amp;style=none&amp;taskId=u1d586af3-8bad-46a6-8b3a-ce9bfff1c16&amp;title=&amp;width=1000" alt=image.png></p><p>实验中对应的不同扫描组合形式</p><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715943140091-57d30060-2f88-47fb-bee5-3f32b5e43940.png#averageHue=%23f8f7f5&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=441&amp;id=ue056f864&amp;originHeight=551&amp;originWidth=712&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=124591&amp;status=done&amp;style=none&amp;taskId=u9056e286-7d60-4de8-a336-c999cb48863&amp;title=&amp;width=569.6" alt=image.png></p><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715943150640-6a7201b5-b365-4d58-bc82-24b96c8e041a.png#averageHue=%23f9f7f5&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=439&amp;id=uc9f513de&amp;originHeight=549&amp;originWidth=719&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=122004&amp;status=done&amp;style=none&amp;taskId=u347dae16-e415-4986-b8a8-460620e03cc&amp;title=&amp;width=575.2" alt=image.png></p><p><img loading=lazy src="https://cdn.nlark.com/yuque/0/2024/png/192314/1715943160061-05f97164-5ace-4f2c-874a-af9e3293851a.png#averageHue=%23f8f6f4&amp;clientId=uf978a707-8366-4&amp;from=paste&amp;height=440&amp;id=uafe64cea&amp;originHeight=550&amp;originWidth=755&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=142247&amp;status=done&amp;style=none&amp;taskId=u678294d0-e738-4e9d-aeb1-4451dd12288&amp;title=&amp;width=604" alt=image.png></p><p>在实验中使用的所有三个数据集上观察到一个有趣的现象。22 种扫描策略产生的分割精度似乎相似。考虑到每个数据集内不同扫描策略之间的小性能差异，以及单个扫描策略在所有三个数据集中的性能差异，没有明显迹象表明任何特定的扫描策略都优于其他方法，无论它们的复杂性或涉及单个或多个扫描方向。观察到的任何轻微的性能波动都可能归因于训练过程的随机性。</p><h2 id=总结>总结
<a hidden class=anchor href=#%e6%80%bb%e7%bb%93><svg viewBox="0 0 640 512"><path fill="currentcolor" d="M172.5 131.1c55.6-55.59 148-55.59 203.6.0 50 50 57.4 129.7 16.3 187.2L391.3 319.9C381 334.2 361 337.6 346.7 327.3c-14.4-10.3-17.8-30.3-7.5-44.6L340.3 281.1C363.2 249 359.6 205.1 331.7 177.2c-31.4-31.4-82.5-31.4-114 0L105.5 289.5c-31.51 30.6-31.51 82.5.0 114C133.3 431.4 177.3 435 209.3 412.1L210.9 410.1C225.3 400.7 245.3 404 255.5 418.4 265.8 432.8 262.5 452.8 248.1 463.1L246.5 464.2c-58.4 41.1-136.3 34.5-186.29-15.4-56.469-56.5-56.469-148.1.0-204.5L172.5 131.1zM467.5 380c-56.5 56.5-148 56.5-204.5.0-50-50-56.5-128.8-15.4-186.3L248.7 192.1C258.1 177.8 278.1 174.4 293.3 184.7 307.7 194.1 311.1 214.1 300.8 229.3L299.7 230.9C276.8 262.1 280.4 306.9 308.3 334.8c31.4 31.4 82.5 31.4 114 0L534.5 222.5c31.5-31.5 31.5-83.4.0-114C506.7 80.63 462.7 76.99 430.7 99.9L429.1 101C414.7 111.3 394.7 107.1 384.5 93.58 374.2 79.2 377.5 59.21 391.9 48.94L393.5 47.82C451 6.731 529.8 13.25 579.8 63.24c56.5 56.46 56.5 148.06.0 204.46L467.5 380z"/></svg></a></h2><p>对于高分辨率遥感图像的语义分割，利用特定的扫描方向或不同扫描方向的组合，如现有的基于 mamba 的方法所提出的策略，并不能有效提高分割精度。因此，在 vision mamba 框架中，使用类似 ViT 的扁平化方法 (即，D1 扫描) 对于此类图像的语义分割仍然有效。此外，采用单向扫描策略 (例如 D1) 也降低了计算需求，从而允许在有限的计算资源内进行更深的网络堆叠。</p><p>探索语言模型在视觉任务上的泛化能力对于深度学习的发展至关重要。基于循环模型的最新进展 [Mamba, RWKV] 中，对将其集成到视觉任务中的有效方法进行着持续探索。当前的工作重点是设计扫描图像 patch 的策略，以增强模型对图像序列的理解。但是本文中对远程感知图像的语义分割的调查表明，基于 mamba 的模型对不同的扫描策略并不敏感。因此，可以说，应该将努力放到探索更有效的方式，而不是探索不同的扫描策略，以增强 mamba 模型对远程感知图像的理解。</p><p>我们的工作并不是要否定 Vision Mamba 为改进扫描策略所做的大量努力，而是要证明这些改进对遥感图像的语义分割效果有限。这种现象是可以解释的：遥感图像在特征方面与传统图像不同。</p><ul><li>一方面，与人物图片等传统图像相比，遥感图像中代表相同语义的斑块在转换成序列时差异很小。</li><li>另一方面，其序列的因果联系也弱于传统图像。</li></ul><p>不过，在其他类型的数据集（如 COCO-Stuff 和 Cityscapes）中，不同的扫描策略在序列中的因果关系更为明显，其有效性还有待验证，这也是未来工作的一个有趣领域。</p><p>在对不同 patch 方法的实验中，我们发现了一个有趣的现象：减小步长可以提高分割精度，但代价是增加了计算需求。这表明，在处理 512×512 像素的图像时，Mamba 在使用比实验中使用的最小步长 4 更小的步长时可能会有更好的表现。但是，由于计算资源有限，较小的步长会使序列长度呈指数增长，因此无法使用这些较小的步长进行实验。研究更高效的计算方法以适应更密集的扫描是未来研究的一个有意义的方向。</p><nav class=pagenav><a class=prev href=/blog/posts/0004-%E8%AF%91%E9%9B%86%E6%88%90%E6%A8%A1%E5%9E%8B%E5%AE%83%E4%BB%AC%E6%98%AF%E4%BB%80%E4%B9%88%E4%BB%A5%E5%8F%8A%E4%BD%95%E6%97%B6%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8%E5%AE%83%E4%BB%AC/><span class=direction>« Prev</span><br><span>【译】集成模型：它们是什么以及何时应该使用它们？ </span></a><a class=next href=/blog/posts/0006-iclr-2024---fastervit---fast-vision-transformers-with-hierarchical-attention/><span class=direction>Next »</span><br><span>ICLR 2024 - FasterViT - Fast Vision Transformers with Hierarchical Attention</span></a></nav></main><footer><div class=copyright>© 2025 Lart Pang</div><div class=attribution>Built with <a href=https://gohugo.io target=_blank>Hugo</a> & <a href=https://github.com/mnjm/kayal target=_blank>Kayal</a></div><div>Last update Jul 17, 2025</div></footer></div><script defer type=text/javascript src=/blog/js/theme.min.eaccfb587dc18aa6c89ddcfe908efce320a265a23826cb3af2032a3f425a36f9b12c233ec2743b2c1017217c7699a7cc7619483ea2257f88b2b63b7b51bbaaa8.js integrity="sha512-6sz7WH3BiqbIndz+kI784yCiZaI4Jss68gMqP0JaNvmxLCM+wnQ7LBAXIXx2mafMdhlIPqIlf4iytjt7UbuqqA=="></script><script defer type=text/javascript src=/blog/js/codecopy.min.6319d0ad3eae498a0591b4ec1d52cc0156f5c3cb95390089d7d0ac7fe6dfb183161c14f935d25b5ad896840e2a9d6a23f555a7976954d0a263c24a11272aa747.js integrity="sha512-YxnQrT6uSYoFkbTsHVLMAVb1w8uVOQCJ19Csf+bfsYMWHBT5NdJbWtiWhA4qnWoj9VWnl2lU0KJjwkoRJyqnRw=="></script><script defer type=text/javascript src=/blog/js/search.min.ad22883b43082f62bc508d1f4e145eb2c6192213144784eadc12e3144ab7af50f826fde65c4a45a68d381b1335f3ff2c189221533436acdffe2c5abd589ce6b8.js integrity="sha512-rSKIO0MIL2K8UI0fThRessYZIhMUR4Tq3BLjFEq3r1D4Jv3mXEpFpo04GxM18/8sGJIhUzQ2rN/+LFq9WJzmuA=="></script></body></html>